<!DOCTYPE html>
<html>
    <head>
        







<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />


    <link rel="shortcut icon" href="/images/favicon-16x16.png" />


<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link
    href="https://fonts.googleapis.com/css2?family=PT+Serif:ital,wght@0,400;0,700;1,400;1,700&display=swap"
    rel="stylesheet"
/>
<link
    href="https://cdn.jsdelivr.net/npm/@fontsource/cascadia-code@4.2.1/index.min.css"
    rel="stylesheet"
/>


<link rel="stylesheet" href="/styles/main.css">


    
<link rel="stylesheet" href="/styles/post.css">



<title>[Summary] R-CNN - Pierre&#39;s Blog</title>

    <meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Pierre's Blog" type="application/atom+xml">
</head>
    <body>
        <header>
    <h1>Pierre&#39;s Blog</h1>
    <nav>
        <ul>
            <li><a href="/">Home</a></li>
            
                
                    <li>
                        <a href="/tags"
                            ><span>Tags</span></a
                        >
                    </li>
                
                    <li>
                        <a href="/categories"
                            ><span>Categories</span></a
                        >
                    </li>
                
                    <li>
                        <a href="/archives"
                            ><span>Archives</span></a
                        >
                    </li>
                
            
        </ul>
    </nav>
</header>

        <main>
    <header>
        <h1>
            
                [Summary] R-CNN
            
        </h1>
        <div>
            <time>2023-03-31</time>
            <div class="post-categories">
                
                    <span class="category-tree">
                        
                            <span class="separator">/</span>
                            <a href="/categories/Note/">Note</a>
                        
                    </span>
                
            </div>
            <div class="post-tags">
                
                    <span class="tag">
                        <span class="separator">#</span>
                        <a href="/tags/CV/">CV</a>
                    </span>
                
            </div>
        </div>
    </header>
    <h1 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h1><blockquote>
<p>Goal: Object recognition<br>Paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1311.2524">https://arxiv.org/abs/1311.2524</a></p>
</blockquote>
<h2 id="Region-proposals"><a href="#Region-proposals" class="headerlink" title="Region proposals"></a>Region proposals</h2><p>Use selective search to extract 2000 region proposals per image.</p>
<h3 id="Selective-search"><a href="#Selective-search" class="headerlink" title="Selective search"></a><a target="_blank" rel="noopener" href="http://www.huppelen.nl/publications/selectiveSearchDraft.pdf"><strong>Selective search</strong></a></h3><p>First use <a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1023/b:visi.0000022288.19776.77">[13] Efficient Graph-Based Image Segmentation</a> to create initial regions. Then calculate the similarties \(s(r_i,r_j)\) between every neighbouring regions. The similarity contains four parts \(s_{color}\), \(s_{texture}\), \(s_{size}\) and \(s_{fill}\), these measures are all in range \([0,1]\).</p>
<ol>
<li>\(s_{color}(r_i,r_j)\) measures color similarity for a regular RGB or HSV image it obtains histograms using 25 bins for each channel \(C_i &#x3D; {c_i^1,â€¦,c_i^{n}}\) \(n&#x3D;25\times3\) (The histograms are normalized using L1-norm) and the similarity is measured using histogram intersection \(s_{color}(r_i,r_j)&#x3D;\sum\limits_{k&#x3D;1}^{n}min(c_i^k,c_j^k)\).</li>
<li>\(s_{texture}(r_i,r_j)\) measures texture similarity, it represents texture using SIFT-like algorithm which takes Gaussian derivatives in eight directions. Then for each channel it extracts a histogram using 10 bins \(T_i &#x3D; \set{t_i^1,\dots,t_i^{n}}\) \(n&#x3D;8\times10\times3\) (The histograms are normalized using L1-norm) abd the similarity is measured using histogram intersection \(s_{texture}(r_i,r_j)&#x3D;\sum\limits_{k&#x3D;1}^{n}min(t_i^k,t_j^k)\).</li>
<li>\(s_{size}(r_i, r_j)\) in order to prevent a single region keeps merging other regions, this algorithm obtains a button up approach to encourage small regions to merge early \(s_{size}(r_i,r_j)&#x3D;1-\dfrac{size(r_i)+size(r_j)}{size(im)}\), \(size(r)\) gives the size of region \(r\) in pixels.</li>
<li>\(s_{fill}(r_i,r_j)\) measures how well two regions fit into each other in order to fill gaps and avoid any holes in merging process. Define \(BB_{ij}\) to be a bounding box around \(r_i\) and \(r_j\). \(s_{fill}(r_i,r_j)&#x3D;1-\dfrac{size(BB_{ij})-size(r_i)-size(r_j)}{size(im)}\)</li>
</ol>
<p>The final similarity is the combination of the four measures where \(a_i\) is either \(0\) or \(1\).<br>$$<br>s(r_i,r_j)&#x3D;a_1s_{color}(r_i,r_j)+a_2s_{texture}(r_i,r_j)+a_3s_{size}(r_i,r_j)+a_4s_{fill}(r_i,r_j)<br>$$</p>
<p><img src="/2023/03/31/rcnn/PpfvPAi.png"></p>
<h2 id="Feature-extraction"><a href="#Feature-extraction" class="headerlink" title="Feature extraction"></a>Feature extraction</h2><p>First, the arbitrary-shaped regions are warped to the required size. Then the extraction step is done by foward a <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/44788133/how-does-mean-image-subtraction-work">mean-substracted</a> 227x227 RGB image through AlexNet which is pre-trained on ImageNet dataset.<br><img src="/2023/03/31/rcnn/kDeVHFb.png"></p>
<blockquote>
<p>Here might be confusing as the original paper <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a> states that the size of input image is 224x224. According to <a target="_blank" rel="noopener" href="https://datascience.stackexchange.com/questions/29245/what-is-the-input-size-of-alex-net">this discussion</a> this is a mistake, the layer size will only make sense if the input size is 227x227. Moreover, Caffe framework, whick is used in this paper, expects the same input size as well.</p>
</blockquote>
<h2 id="Classify-regions"><a href="#Classify-regions" class="headerlink" title="Classify regions"></a>Classify regions</h2><p>After extracting feature vector for every region proposals, each feature vector is then scored by the SVM trained for each class.</p>
<h2 id="Bounding-box-regression"><a href="#Bounding-box-regression" class="headerlink" title="Bounding box regression"></a>Bounding box regression</h2><p>Predict a new bounding box for the detection using a class-specific bounding box regressor as the bounding box extracted by selective search might have a relative low IoU. By adjusting the bounding box closer to ground-truth, we can get a more accurate detection result.</p>
<p>Input of the regressor is a set of training pairs \({(P^i, G^i)}_{i&#x3D;1,\dots,N}\), where \(P^i&#x3D;(P_x^i,P_y^i,P_w^i,P_h^i)\) is the proposal bounding box and \(G^i&#x3D;(G_x^i,G_y^i,G_w^i,G_h^i)\) is the ground-truth bounding box. The goal is to find a transformation that maps \(P\) to \(G\).<br>$$<br>\displaylines{<br>  \hat{G}_x&#x3D;P_wd_x(P)+P_x\\<br>  \hat{G}_y&#x3D;P_hd_y(P)+P_y\\<br>  \hat{G}_w&#x3D;P_w\ \text{exp}(d_w(P))\\<br>  \hat{G}_h&#x3D;P_h\ \text{exp}(d_h(P))<br>}<br>$$</p>
<p>\(d_x\), \(d_y\) specify a <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/55553747/what-is-scale-invariance-and-log-space-translations-of-a-bounding-box">scale-invarient</a> translation of the center of the bounding box, while \(d_w\), \(d_h\) specify a log-space translation. Transform function is modeled as \(d_\star(P)&#x3D;\textbf{w}_\star^T\phi_5(P),\ \star \in \set{ x, y, w, h }\) where \(\phi_5(P)\) is the feature vector output by pool5 of the CNN used in feature extraction, \(\textbf{w}_\star\) is a learnable model parameter vector. This paper applies SSE(Error Sum of Squares) loss with L2 regularization.</p>
<p>$$<br>\displaylines{<br>  \mathcal{L} &#x3D; \sum_{i}^{N}(t^i_\star-d_\star(P^i))^2+\lambda\lVert{\hat{\textbf{w}}_\star}\rVert^2 \\<br>  \textbf{w}_\star &#x3D; \underset{\hat{\textbf{w}}_\star}{\text{argmin}}\ \mathcal{L}<br>}<br>$$</p>
<p>$$<br>\displaylines{<br>  t_x &#x3D; (G_x-P_x)&#x2F;P_x \\<br>  t_y &#x3D; (G_y-P_y)&#x2F;P_y \\<br>  t_w &#x3D; \text{log}(G_w&#x2F;P_w) \\<br>  t_h &#x3D; \text{log}(G_h&#x2F;P_h)<br>}<br>$$</p>

    <div class="gallery">
        
    </div>
</main>

        
    <nav class="pagination">
        <span class="prev">
            
                <a href="/2024/06/08/ais3-pre-exam-2024/">
                    AIS3 2024 Pre-Exam Writeup
                </a>
            
        </span>
        <span class="next">
            
                <a href="/2023/02/18/incognito-4/" >
                    Incognito CTF 4.0
                </a>
            
        </span>
    </nav>


        <footer>
    <p>&copy; Pierre</p>
    <p>
        Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>,
        <a target="_blank" rel="noopener" href="https://github.com/sunnybyeon/hexo-theme-dashed">Theme</a> by
        <a target="_blank" rel="noopener" href="https://github.com/sunnybyeon">sunnybyeon</a>
    </p>
    
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [['$$', '$$'],['\\[','\\]']],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js "></script>

    
</footer>

    </body>
</html>
